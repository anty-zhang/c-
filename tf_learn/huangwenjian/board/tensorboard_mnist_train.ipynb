{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# tensorboard \n",
    "\n",
    "### 图像说明\n",
    "\n",
    "> 节点间实线的边： 刻画数据传输，边上的箭头表达来数据传输的方向\n",
    "\n",
    "> 节点间虚线的边： 表达来计算之间的依赖关系\n",
    "\n",
    "> 效果图上边的粗细表示的是两个节点之间传输的标量维度的总大小\n",
    "\n",
    "> \n",
    "\n",
    "### 主要作用\n",
    "\n",
    "> 可视化神经网络的结构\n",
    "\n",
    "> 记录每一个节点信息以及运行时消耗的时间和空间\n",
    "\n",
    "\n",
    "### 日志生成函数与TensorBorad界面对应关系\n",
    "\n",
    "> tf.scalar_summary --> EVENTS [TensorFlow中标量监控数据随着迭代进行的变化趋势]\n",
    "\n",
    "> tf.image_summary --> IMAGES [TensorFlow中使用的图片数据]\n",
    "\n",
    "> tf.audio_summary --> AUDIO [TensorFlow中使用的音频数据]\n",
    "\n",
    "> tf.histogram_summary --> HISTOGRAM [TensorFlow中张量分布监控数据随着迭代数的变化趋势]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# 使用命名空间改造mnist训练程序，以便在tensorboard观察训练过程\n",
    "# tensorflow 使用mnist训练神经网络实例\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import mnist_inference\n",
    "\n",
    "###################################################################################################\n",
    "# mnist 数据集相关常数\n",
    "# 输入层节点数。 对于mnist数据集，这个等于图片的像素\n",
    "INPUT_NODE = 784\n",
    "# 输出层的节点数。这个等于类别的数目\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "###################################################################################################\n",
    "# 配置神经网络参数\n",
    "# 隐藏层节点数\n",
    "LAYER1_NODE = 500\n",
    "# 一个训练batch中的训练数据个数， batch越大，训练越接近梯度下降；batch越小，训练越接近随机梯度下降\n",
    "BATCH_SIZE = 100\n",
    "# 基础学习率\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "# 学习率衰减率\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "# 描述模型复杂度的正则化项在损失函数中的系数\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "# 训练论数\n",
    "TRAINING_STEPS = 2000\n",
    "# 滑动平均衰减率\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "\n",
    "###################################################################################################\n",
    "# 训练模型\n",
    "def train(mnist):\n",
    "    # 将处理输入数据的计算都放在名字为“input”的命名空间下\n",
    "    with tf.name_scope(\"input1\"):\n",
    "        x = tf.placeholder(tf.float32, [None, INPUT_NODE], name=\"x-input\")\n",
    "        y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name=\"y-input\")\n",
    "        \n",
    "    # 计算L2正则化损失函数\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    y = mnist_inference.inference(x, regularizer)\n",
    "    # 定义存储训练轮数的变量\n",
    "    # 此变量不需要计算滑动平均值，所以这里指定这个变量为不可训练的变量\n",
    "    # 在tensorflow训练神经网络时，一般会将嗲表训练轮数的变量指定为不可训练的变量\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "    # 将处理滑动平均模型的相关计算都放在moving_arvrage的命名空间下\n",
    "    with tf.name_scope(\"moving_arverage\"):\n",
    "        # 给定滑动平均衰减率和训练轮数的变量，初始化滑动平均类；给定训练轮数的变量可以加快训练早期变量的更新速度\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "        # 在所有代表神经网络参数的变量上使用滑动平均（辅助变量不需要）\n",
    "        # tf.trainable_variables返回的就是图上集合GraphKeys.TRAINABLE_AVERAGES中的元素。这个集合的元素就是所有没有指定\n",
    "        # trainable=False的参数\n",
    "        variable_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    # 将计算损失函数相关的计算放在loss_function的命名空间下\n",
    "    with tf.name_scope(\"loss_function\"):\n",
    "        # 计算交叉熵作为刻画预测值和真实值之间差距的损失函数\n",
    "        # 当分类问题只有一个正确答案时，可以使用sparse_softmax_cross_entropy_with_logits函数来加速交叉熵计算\n",
    "        # tf.argmax函数得到正确答案对应的类别编号\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(y, tf.argmax(y_, 1))\n",
    "        # 计算在当前batch中所有样例的交叉熵平均值\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "        # 总损失等于交叉熵损失和正则化损失之和\n",
    "        loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses'))\n",
    "    \n",
    "    # 将学习率，优化方法以及每一轮训练需要执行的操作放在train_step命名空间下\n",
    "    with tf.name_scope(\"train_step\"):\n",
    "        # 设置指数衰减的学习率\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            LEARNING_RATE_BASE,    # 基础学习率，随着迭代的进行，更新变量时使用的学习率在这个基础上递减 \n",
    "            global_step,           # 当前迭代的轮数\n",
    "            mnist.train.num_examples/BATCH_SIZE,    # 总的迭代次数\n",
    "            LEARNING_RATE_DECAY)                    # 学习率递减速度\n",
    "        # 使用tf.train.GradientDescentOptimizer优化算法来优化损失函数\n",
    "        # 这里的损失函数包括了交叉熵损失和L2正则化损失\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "        \n",
    "        with tf.control_dependencies([train_step, variable_averages_op]):\n",
    "            train_op = tf.no_op(name='train')\n",
    "    # 将当前的计算图输出到TensorBorad日志文件中\n",
    "    writer = tf.train.SummaryWriter(\"/data/tmp/tensor_test.log\", tf.get_default_graph())\n",
    "    \n",
    "    # 训练模型\n",
    "    # 初始化会话并开始训练过程\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        # 迭代的训练神经网络\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            # 产生这一轮使用的一个batch的训练数据，并运行训练过程\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            if i % 1000 ==0:\n",
    "                # 配置运行时需要记录的信息\n",
    "                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                # 记录运行时的信息proto\n",
    "                run_metadata = tf.RunMetadata()\n",
    "                _, loss_value, step = sess.run(\n",
    "                    [train_op, loss, global_step], feed_dict={x: xs, y_: ys},\n",
    "                    options=run_options, run_metadata=run_metadata)\n",
    "                \n",
    "                writer.add_run_metadata(run_metadata, 'step%3d' % i)\n",
    "                \n",
    "                print \"After %d traning step(s), loss on traning batch is %g.\" % (step, loss_value)\n",
    "            else:\n",
    "                _, loss_value, step = sess.run(\n",
    "                    [train_op, loss, global_step], feed_dict={x: xs, y_: ys})\n",
    "           \n",
    "    writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/xxx/work5/tensorflow/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/xxx/work5/tensorflow/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/xxx/work5/tensorflow/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/xxx/work5/tensorflow/mnist/t10k-labels-idx1-ubyte.gz\n",
      "After 1 traning step(s), loss on traning batch is 2.94731.\n",
      "After 1001 traning step(s), loss on traning batch is 0.305558.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/env/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# 主程序入口\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"/Users/xxx/work5/tensorflow/mnist\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "###################################################################################################\n",
    "# tesorflow提供了一个主程序的入口，tf.app.run会调用上面定义的main函数\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
