{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow 队列\n",
    "\n",
    "### 两种队列\n",
    "\n",
    "> FIFOQueue\n",
    "\n",
    "> RandomShuffleQueue\n",
    "\n",
    "### 多线程协同功能\n",
    "\n",
    "> tf.Coordinator 主要用于协同多个线程一起停止， 并提供should_stop,request_stop,join三个函数\n",
    "\n",
    "> tf.QueueRunner 主要用于启动多个线程来操作同一个队列，启动的线程可以通过tf.Coordinator类统一管理\n",
    "\n",
    "### 输入文件队列\n",
    "\n",
    "> tf.train.match_filenames_once 获取符合一个正则表达式的所有文件\n",
    "\n",
    "> tf.train.string_input_producer 会使用初始化时提供的文件列表创建一个输入队列。此函数生成的输入队列，可以同时被多个文件读取线程操作； 输入队列会将队列中的文件均匀的分给不同的线程。 shuffle为True时，文件加入队列之前会被打乱顺序； num_epochs 限制加载出事文件列表的最大轮数。\n",
    "\n",
    "### 组合batch训练数据\n",
    "\n",
    "> tf.train.batch， tf.train.shuffle_batch 将单个的样例组织成batch的形式输出。 队列的入队操作是生成单个样例的方法，而每次出队列得到的是一个batch的样例\n",
    "\n",
    "> tf.train.shuffle_batch和tf.train.shuffle_batch_join都和完成多线程并行化的方式来进行数据预处理。\n",
    "\n",
    "> tf.train.shuffle_batch，不同的线程会读取同一个文件，但如果一个文件中的样例比较相似，那么神经网络的训练效果可能会受到影响。所以在使用tf.train.shuffle_batch时，需要将同一个TFRecord文件中的样例随机打乱。\n",
    "\n",
    "> tf.train.shuffle_batch_join，不同的线程会读取不同文件。如果读取的线程数比总文件数还大，那么多多个线程可能会读取同一个文件中相近部分的数据。而多个线程读取多个文件可能过的硬盘寻址，从而使得读取效率降低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建队列并操作里面的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Tensor(\"add_3:0\", dtype=int32)\n",
      "10\n",
      "Tensor(\"add_3:0\", dtype=int32)\n",
      "1\n",
      "Tensor(\"add_3:0\", dtype=int32)\n",
      "11\n",
      "Tensor(\"add_3:0\", dtype=int32)\n",
      "2\n",
      "Tensor(\"add_3:0\", dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建一个先进先出队列，指定队列中最多可以保存的两个元素，并指定类型为整数\n",
    "q = tf.FIFOQueue(2, 'int32')\n",
    "\n",
    "# 使用enqueue_many初始化队列中的元素\n",
    "init = q.enqueue_many(([0, 10], ))\n",
    "\n",
    "# 使用dequeue将队列中的第一个元素出队列\n",
    "x = q.dequeue()\n",
    "y = x + 1\n",
    "q_inc = q.enqueue([y])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 运行初始化队列\n",
    "    init.run()\n",
    "    for _ in range(5):\n",
    "        v, v1 = sess.run([x, q_inc])\n",
    "        \n",
    "        # 打印出队列取值\n",
    "        print v\n",
    "        \n",
    "        print y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多线程协调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoping from id: 0\n",
      "working on id: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 线程中运行的程序，每隔1秒钟判断是否需要停止并打印自己的ID\n",
    "\n",
    "def MyLoop(coord, worker_id):\n",
    "    # 使用tf.Coordinator类提供的协同工具判断当前线程是否需要停止\n",
    "    while not coord.should_stop():\n",
    "        # 随机停止所有的线程\n",
    "        if np.random.rand() < 0.1:\n",
    "            print \"Stoping from id: %d\\n\" % worker_id\n",
    "            # 调用coord.request_stop通知其它线程停止\n",
    "            coord.request_stop()\n",
    "        else:\n",
    "            print \"working on id: %d\\n\" % worker_id\n",
    "        time.sleep(1)\n",
    "\n",
    "# 声明一个tf.train.Coordinator类来协同多个线程\n",
    "coord = tf.train.Coordinator()\n",
    "# 声明5个线程\n",
    "threads = [threading.Thread(target=MyLoop, args=(coord, i, )) for i in xrange(5)]\n",
    "# 启动所有线程\n",
    "for t in threads:\n",
    "    t.start()\n",
    "# 等待所有线程推出\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多个线程操作一个(写)队列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.70156\n",
      "-0.751789\n",
      "-0.992687\n"
     ]
    }
   ],
   "source": [
    "# 声明一个先进先出队列，队列中最多100个元素，类型为实数\n",
    "queue = tf.FIFOQueue(100, \"float\")\n",
    "# 定义队列的入队操作\n",
    "enqueue_op = queue.enqueue([tf.random_normal([1])])\n",
    "\n",
    "# tf.train.QueueRunner创建多个线程运行队列的入队操作\n",
    "# [enqueue_op] * 5 表示需要启动5个线程，每个线程中运行的是enqueue_op操作\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * 5)\n",
    "\n",
    "# 将定义过的QueueRunner加入到TensorFlow计算图上指定的集合\n",
    "# tf.train.add_queue_runner没有指定的集合，则加入默认集合tf.GraphKeys.QUEUE_RUNNERS\n",
    "tf.train.add_queue_runner(qr)\n",
    "\n",
    "# 定义出队列操作\n",
    "out_tensor = queue.dequeue()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 使用tf.train.Coordinator来协同启动线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    # 使用tf.train.QueueRunner时，需要明确调用tf.train.start_queue_runners来启动所有的线程\n",
    "    # tf.train.start_queue_runners会默认启动tf.GraphKeys.QUEUE_RUNNERS集合中所有的QueueRunner\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 获取队列中的取值\n",
    "    for _ in range(3):\n",
    "        print sess.run(out_tensor)[0]\n",
    "    \n",
    "    # 使用tf.train.Coordinator来停止所有的线程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入文件队列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:  /Users/xxx/tmp/data.tfrecords-00000-of-00002\n",
      "filename:  /Users/xxx/tmp/data.tfrecords-00001-of-00002\n"
     ]
    }
   ],
   "source": [
    "# 模拟海量数据情况下将数据写入不同的文件\n",
    "\n",
    "# 创建TFRecord文件\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "# 定西总共写入多少个文件\n",
    "num_shards = 2\n",
    "# 定义每个文件中有多少个数据\n",
    "instances_per_shard = 2\n",
    "\n",
    "for i in range(num_shards):\n",
    "    # 将数据氛围多个文件时，命令方式0000n-of-0000m后缀区分。\n",
    "    # m表示数据总共被存在来多少个文件中，n表示当前文件的编号\n",
    "    filename = ('/Users/xxx/tmp/data.tfrecords-%.5d-of-%.5d' % (i, num_shards))\n",
    "    print \"filename: \", filename\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    # 将数据封装成Example结构并写入TFRecord文件 \n",
    "    for j in range(instances_per_shard):\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'i': _int64_feature(i),\n",
    "            'j': _int64_feature(j)\n",
    "        }))\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/xxx/tmp/data.tfrecords-00000-of-00002'\n",
      " '/Users/xxx/tmp/data.tfrecords-00001-of-00002']\n",
      "[0, 0]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[1, 1]\n",
      "[0, 0]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[1, 1]\n",
      "[0, 0]\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 文件队列操作\n",
    "\n",
    "# 使用tf.train.match_filenames_once获取文件列表\n",
    "files = tf.train.match_filenames_once(\"/Users/xxx/tmp/data.tfrecords-*\")\n",
    "\n",
    "# 使用tf.train.string_input_producer创建输入队列\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=False)\n",
    "\n",
    "# 读取并解析一个样本\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "features = tf.parse_single_example(serialized_example,\n",
    "                                  features={\n",
    "                                   'i': tf.FixedLenFeature([], tf.int64),\n",
    "                                    'j': tf.FixedLenFeature([], tf.int64)\n",
    "                                  })\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 虽然本段程序没有声明任何变量，但使用tf.train.match_filenames_once函数时需要初始化一些变量\n",
    "    tf.initialize_all_variables().run()\n",
    "    \n",
    "    # 打印文件列表\n",
    "    print sess.run(files)\n",
    "    \n",
    "    # 声明tf.train.Coordinator类协同不同的线程，并启动线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 多次执行获取数据的操作\n",
    "    for i in range(10):\n",
    "        print sess.run([features['i'], features['j']])\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example:  Tensor(\"ParseSingleExample_2/Squeeze_i:0\", shape=(), dtype=int64)  ,label:  Tensor(\"ParseSingleExample_2/Squeeze_j:0\", shape=(), dtype=int64)\n",
      "cur_example_batch:  [0 0 1]  ,cur_label_batch:  [0 1 0]\n",
      "cur_example_batch:  [0 1 1]  ,cur_label_batch:  [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 组合训练数据batching\n",
    "# 这里假设Example结构中i表示一个样例的特征向量，j表示样例对应的标签\n",
    "example, label = features['i'], features['j']\n",
    "print \"example: \", example, \" ,label: \", label\n",
    "\n",
    "# 一个batch中样例的个数\n",
    "batch_size = 3\n",
    "\n",
    "# 组合样例的队列中最多可以存储的样例个数。 一般这个队列的大小会和每一个batch的大小相关\n",
    "# 如果队列太大，那么需要占用很多内存资源； 如果太小，那么出队列可以会因为没有数据而被阻碍，从而导致训练效率降低\n",
    "capacity = 1000 + 3 * batch_size\n",
    "\n",
    "# 使用tf.train.batch组合样例\n",
    "# [example, label]参数给出类需要组合的元素\n",
    "# batch_size 参数给出了每个batch中样例的个数\n",
    "# capacity给出了队列的最大容量。 \n",
    "# 当队列长度等于最大容量时，Tensorflow将暂停入队操作，而只是等待元素出队；当元素个数小于容量时，将自动重新启动入队操作\n",
    "example_batch, label_batch = tf.train.batch([example, label], batch_size=batch_size, capacity=capacity)\n",
    "\n",
    "# 使用tf.train.shuffle_batch组合样例\n",
    "# min_after_dequeue参数限制类出队列时队列中元素的最少个数\n",
    "# 当队列中元素个数太少时，随机打乱样例的顺序作用就不大\n",
    "# num_threads参数，可以指定多个线程同时执行入队操作。当大于1时，多个线程会同时去读一个文件中的不同样例并进行预处理（重要）\n",
    "# example_batch, label_batch = tf.train.shuffle_batch([example, label], \n",
    "#                                                     batch_size=batch_size, capacity=capacity, min_after_dequeue==30)\n",
    "\n",
    "# 使用tf.train.shuffle_batch_join组合样例\n",
    "# 此函数会从输入文件队列中获取不同的文件分配给不同的线程\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 获取并打印组合之后的样例\n",
    "    for i in range(2):\n",
    "        cur_example_batch, cur_label_batch = sess.run([example_batch, label_batch])\n",
    "        print 'cur_example_batch: ', cur_example_batch,' ,cur_label_batch: ', cur_label_batch\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
