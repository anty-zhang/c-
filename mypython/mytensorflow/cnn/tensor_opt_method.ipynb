{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "7.5\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# 正则化测试实例\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "weight = tf.constant([[1.0, -2.0], [-3.0, 4.0]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # (|1.0| + |-2.0| + |-3.0| + |4.0|) * 0.5 = 5\n",
    "    print sess.run(tf.contrib.layers.l1_regularizer(.5)(weight))\n",
    "    # (1.0^2 + (-2.0)^2 + (-3.0)^2 + (4.0)^2 * 0.5 = 7.5\n",
    "    print sess.run(tf.contrib.layers.l2_regularizer(.5)(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_1:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_2:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_3:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_4:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_5:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_6:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_7:0' shape=() dtype=float32>, <tf.Tensor 'Mean:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_8:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_9:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_10:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_11:0' shape=() dtype=float32>, <tf.Tensor 'Mean_1:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_12:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_13:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_14:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_15:0' shape=() dtype=float32>, <tf.Tensor 'Mean_2:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_16:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_17:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_18:0' shape=() dtype=float32>, <tf.Tensor 'l2_regularizer_19:0' shape=() dtype=float32>, <tf.Tensor 'Mean_3:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# 正则化测试实例\n",
    "# 通过集合的方法计算5层全连接神经网络结构L2正则化的损失函数\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "batch_size = 8\n",
    "\n",
    "# 定义每一层网络节点个数\n",
    "layer_dimension = [2, 10, 10, 10, 1]\n",
    "n_layers = len(layer_dimension)    # 神经网络的层数\n",
    "cur_layer = x     # cur_layer 维护前向传播时最深层的节点，初始为输入层\n",
    "in_dimension = layer_dimension[0]    # 当前层节点个数\n",
    "\n",
    "\n",
    "# 获取每一层边上的权重，并将这个权重的L2正则化损失加入名称“losses”的集合中\n",
    "def get_weight(shape, _lambda):\n",
    "    # 生成一个shape维度的变量\n",
    "    var = tf.Variable(tf.random_normal(shape), dtype=tf.float32)\n",
    "    # add_to_collection 将这个新生成的变量的L2正则损失加入到集合中\n",
    "    tf.add_to_collection(\"losses\", tf.contrib.layers.l2_regularizer(_lambda)(var))\n",
    "    return var\n",
    "\n",
    "\n",
    "# 通过循环生成一个5层全连接的神经网络结构\n",
    "for i in range(1, n_layers):\n",
    "    out_dimension = layer_dimension[i]    # 下一层节点个数\n",
    "    # 生成当前层中权重的变量，并将这个变量的L2正则化损失加入计算图上的集合中\n",
    "    weight = get_weight([in_dimension, out_dimension], 0.001)\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[out_dimension]))\n",
    "    \n",
    "    # 使用relu激活函数\n",
    "    cur_layer = tf.nn.relu(tf.matmul(cur_layer, weight) + bias)\n",
    "    # 进入下一层节点之前将下一层的节点更新为当前节点的个数\n",
    "    in_dimension = out_dimension\n",
    "    \n",
    "\n",
    "# \n",
    "mse_loss = tf.reduce_mean(tf.square(y_ - cur_layer))\n",
    "\n",
    "tf.add_to_collection(\"losses\", mse_loss)\n",
    "\n",
    "print tf.get_collection(\"losses\")\n",
    "\n",
    "# get_collection 返回一个列表，存放的是损失函数的不同部分，将其全部加起来即为最终的损失函数\n",
    "loss = tf.add_n(tf.get_collection(\"losses\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "通过ema.average(v1)获取滑动平均之后变量的取值\n",
      "[0.0, 0.0]\n",
      "更新变量v1的值到5\n",
      "[5.0, 4.5]\n",
      "step=10000， v1 = 10, 更新v1的滑动平均值\n",
      "[10.0, 4.5549998]\n",
      "再次更新滑动平均值\n",
      "[10.0, 4.6094499]\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# 滑动平均模型使用\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 定义一个变量用来计算滑动平均变量，初始值设置0.\n",
    "v1 = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "# 定义一个模拟神经网络中迭代的轮数变量，用来动态控制衰减率\n",
    "step = tf.Variable(0, trainable=False)\n",
    "\n",
    "# 定义一个滑动平均类（class）。 初始化时给定衰减率和控制衰减率的变量step\n",
    "ema = tf.train.ExponentialMovingAverage(0.99, step)\n",
    "\n",
    "# 定义一个更新滑动平均的操作。 这里需要给定一个列表，每次执行这个操作时这个列表中的变量都会更新\n",
    "maintain_average_op = ema.apply([v1])\n",
    "\n",
    "###################################################################################################\n",
    "# 训练结果\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化所有变量\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # 通过ema.average(v1)获取滑动平均之后变量的取值\n",
    "    print \"通过ema.average(v1)获取滑动平均之后变量的取值\"\n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "    \n",
    "    # 更新变量v1的值到5\n",
    "    print \"更新变量v1的值到5\"\n",
    "    sess.run(tf.assign(v1, 5))\n",
    "    # 更新v1的滑动平均值。 衰减率为： min{0.99, (1 + step) / (10 + step) = 0.1} = 0.1\n",
    "    # 所以v1的滑动平均会更新为 0.1 * 0 + 0.9 * 5 = 4.5\n",
    "    sess.run(maintain_average_op)\n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "    \n",
    "    # step=10000， v1 = 10, 更新v1的滑动平均值\n",
    "    # 衰减率为： min{0.99, (1 + step) / (10 + step) = 0.999} = 0.99\n",
    "    # v1 的滑动平均值更新为： 0.99 * 4.5 + 0.01 * 10 = 4.555\n",
    "    print \"step=10000， v1 = 10, 更新v1的滑动平均值\"\n",
    "    sess.run(tf.assign(step, 10000))\n",
    "    sess.run(tf.assign(v1, 10))\n",
    "    sess.run(maintain_average_op)\n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "    \n",
    "    print \"再次更新滑动平均值\"\n",
    "    # 再次更新滑动平均值\n",
    "    # v1 的滑动平均值更新为：0.99 * 4.5549998 + 0.01 * 10 = 4.60945\n",
    "    sess.run(maintain_average_op)\n",
    "    print sess.run([v1, ema.average(v1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}